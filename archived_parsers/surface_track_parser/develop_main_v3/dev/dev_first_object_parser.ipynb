{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import yaml\n",
    "import os\n",
    "from collections.abc import MutableMapping\n",
    "from typing import Dict, List, Tuple\n",
    "from exceptions import *\n",
    "from copy import deepcopy\n",
    "import collections\n",
    "from parser_base import Parser\n",
    "from imaris import ImarisDataObject\n",
    "import ray\n",
    "from functools import partial\n",
    "import time\n",
    "import polars as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = (\n",
    "    \"../../data/multi_surface_track_parser_dev_data/GFP #1 Sec2 Roi1 2x2 1h30min.ims\"\n",
    ")\n",
    "os.path.isfile(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @ray.remote\n",
    "class TimeStepSurfaceParser(Parser):\n",
    "    \"\"\"\n",
    "    Extracts Surface information for a given time step Imaris File\n",
    "\n",
    "    Args:\n",
    "        Parser (ABCMeta): Parser Abstract Base Class\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, ims_file_path: str, time_step: float = 1.0) -> None:\n",
    "        self.time_step = time_step\n",
    "        self.ims_file_path = ims_file_path\n",
    "        self.ims = ImarisDataObject(self.ims_file_path)\n",
    "        self.configure_instance()\n",
    "\n",
    "    def configure_instance(self) -> None:\n",
    "        \"\"\"\n",
    "        Extracts relevant information from ims object and\n",
    "        instantiates it as instance variables for fast recall.\n",
    "\n",
    "        Currently Extracts:\n",
    "            - all the surface names -- List\n",
    "            - all the stats_names -- {id: pd.DataFrame}\n",
    "            - all the stats values -- {id: pd.DataFrame}\n",
    "            - all the factor info -- {id: pd.DataFrame}\n",
    "        \"\"\"\n",
    "        # TODO: check to ensure surfaces exist or raise error\n",
    "        # extract all information and saves it as a instance var\n",
    "        self.surface_names = self.ims.get_object_names(\"Surface\")\n",
    "\n",
    "        # get all the stats names for every surface {surf_id: stats_name_df}\n",
    "        self.stats_names = {\n",
    "            surface_id: self.ims.get_stats_names(surface_name)\n",
    "            for surface_id, surface_name in enumerate(self.surface_names)\n",
    "        }\n",
    "\n",
    "        # get all the stats values for every surface {surf_id: stats_values_df}\n",
    "        self.stats_values = {\n",
    "            surface_id: self.ims.get_stats_values(surface_name)\n",
    "            for surface_id, surface_name in enumerate(self.surface_names)\n",
    "        }\n",
    "\n",
    "        # get all the factor table info for every surface {surf_id: factor_df}\n",
    "        self.factors = {\n",
    "            surface_id: self.ims.get_object_factor(surface_name)\n",
    "            for surface_id, surface_name in enumerate(self.surface_names)\n",
    "        }\n",
    "\n",
    "        # get all the factor table info for every surface {surf_id: factor_df}\n",
    "        self.object_ids = {\n",
    "            surface_id: self.ims.get_object_ids(surface_name)\n",
    "            for surface_id, surface_name in enumerate(self.surface_names)\n",
    "        }\n",
    "\n",
    "    def organize_stats(self, stats_values: pd.DataFrame) -> Dict:\n",
    "        \"\"\"Organized the data such that it looks like\n",
    "        {ID_Object: {Stats Name: Value}}\n",
    "\n",
    "        Args:\n",
    "            surface_stats_values (pd.DataFrame): a single dataframe\n",
    "            that contains the statistics for a single surface\n",
    "\n",
    "        Returns:\n",
    "            Dict: _description_\n",
    "        \"\"\"\n",
    "        grouped_stats = (\n",
    "            stats_values.groupby(\"ID_Object\")[[\"ID_StatisticsType\", \"Value\"]]\n",
    "            .apply(lambda x: x.set_index(\"ID_StatisticsType\").to_dict(orient=\"dict\"))\n",
    "            .to_dict()\n",
    "        )\n",
    "        grouped_stats = {k: v[\"Value\"] for k, v in grouped_stats.items()}\n",
    "        return grouped_stats\n",
    "\n",
    "    def generate_csv(\n",
    "        self, stats_values: Dict, stat_names: pd.DataFrame\n",
    "    ) -> pd.DataFrame:\n",
    "        \"\"\"_summary_\n",
    "\n",
    "        Args:\n",
    "            organized_stats (Dict): _description_\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: _description_\n",
    "        \"\"\"\n",
    "        # create a dict that maps stat_id to stat_name\n",
    "        column_names_dict = dict(zip(stat_names[\"ID\"], stat_names[\"Name\"]))\n",
    "        dataframe = pd.DataFrame(stats_values).transpose()\n",
    "\n",
    "        # replaces id columns with respective stat name and add idx\n",
    "        dataframe = dataframe.rename(column_names_dict, axis=1)\n",
    "        dataframe[\"Object_ID\"] = dataframe.index\n",
    "        return dataframe\n",
    "\n",
    "    def save_csv(self):\n",
    "        # a function to write csv information to disk\n",
    "        pass\n",
    "\n",
    "    def process(self, surface_id: int) -> None:\n",
    "        \"\"\"\n",
    "        Runs a single end to end parser pipeline on a single surface\n",
    "        Steps:\n",
    "            - get stat names for a single surface\n",
    "            - get stat values for a single surface\n",
    "            - filter stat values to keep only track ids\n",
    "            - filter stats values to remove track level stat information\n",
    "            - rename certian columns (if needed)(need a custom func for this to add channel info)\n",
    "            - organize the filtered stats\n",
    "            - generate csv\n",
    "            - save csv\n",
    "\n",
    "        Args:\n",
    "            surface_id (int): _description_\n",
    "        \"\"\"\n",
    "        # gather info for current surface\n",
    "        start = time.perf_counter()\n",
    "        surface_name = self.surface_names[surface_id]\n",
    "        print(f\"surface_name: {time.perf_counter() - start}\")\n",
    "        stat_names = self.stats_names.get(surface_id)\n",
    "        print(f\"stat_names: {time.perf_counter() - start}\")\n",
    "        stat_values = self.stats_values.get(surface_id)\n",
    "        print(f\"stat_values: {time.perf_counter() - start}\")\n",
    "        track_id = self.object_ids.get(surface_id)\n",
    "        print(f\"object_id: {time.perf_counter() - start}\")\n",
    "        factor = self.factors.get(surface_id)\n",
    "        print(f\"factor: {time.perf_counter() - start}\")\n",
    "\n",
    "        # update channel and surface names\n",
    "        stat_names = self.update_channel_info(stats_names=stat_names, factor=factor)\n",
    "        print(f\"stat_names_channel: {time.perf_counter() - start}\")\n",
    "        stat_names = self.update_surface_info(stats_names=stat_names, factor=factor)\n",
    "        print(f\"stat_names_surfaces: {time.perf_counter() - start}\")\n",
    "\n",
    "        # filter stats values by object ids and time index = self.time_step\n",
    "        time_index_id = stat_names[stat_names[\"Name\"] == \"Time Index\"][\"ID\"]\n",
    "        time_index_id = time_index_id.iloc[0].item()\n",
    "        filtered_stat_values = self.filter_stats(\n",
    "            stats_values=stat_values,\n",
    "            filter_col_names=[\"ID_Object\", \"ID_StatisticsType\", \"Value\"],\n",
    "            filter_values=[\n",
    "                track_id,\n",
    "                pd.Series([time_index_id]),\n",
    "                pd.Series([self.time_step]),\n",
    "            ],\n",
    "        )\n",
    "        print(f\"filtered_stat_values: {time.perf_counter() - start}\")\n",
    "\n",
    "        # organize stats values\n",
    "        organized_stats = self.organize_stats(filtered_stat_values)\n",
    "        print(f\"organized_stats: {time.perf_counter() - start}\")\n",
    "\n",
    "        # generate csv\n",
    "        stats_df = self.generate_csv(organized_stats, stat_names=stat_names)\n",
    "        print(f\"stats_df: {time.perf_counter() - start}\")\n",
    "\n",
    "        return stats_df\n",
    "\n",
    "    def filter_stats(\n",
    "        self,\n",
    "        stats_values: pd.DataFrame,\n",
    "        filter_col_names: List[str],\n",
    "        filter_values: List[pd.Series],\n",
    "    ) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Filters the stats values dataframe. It keeps information\n",
    "        from col_names and filter_values that is passed in as arguments.\n",
    "\n",
    "        Args:\n",
    "            stats_values (pd.DataFrame): _description_\n",
    "            filter_col_name (str): name of the column we want to use to filter\n",
    "            filter_values (str): values that we want to keep\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: _description_\n",
    "        \"\"\"\n",
    "        # for first surface parser we apply 3 filters\n",
    "        # object, statistisc type, and value filters\n",
    "        # to get the object ids that belong to the first time setp\n",
    "        stats_values_copy = deepcopy(stats_values)\n",
    "        for col_names, values in zip(filter_col_names, filter_values):\n",
    "            stats_values_copy = stats_values_copy[\n",
    "                stats_values_copy[col_names].isin(values=values)\n",
    "            ]\n",
    "\n",
    "        # filter the original stats values to only contain the\n",
    "        # information from the first time step\n",
    "        # TODO: maybe doing this with a deepcopy is a good idea\n",
    "        # That way we can chain multiple filters get the final object ids\n",
    "        # and return all the stats for those object ids\n",
    "        stats_values = stats_values[\n",
    "            stats_values[\"ID_Object\"].isin(values=stats_values_copy[\"ID_Object\"])\n",
    "        ]\n",
    "\n",
    "        return stats_values\n",
    "\n",
    "    def extract_and_save(self):\n",
    "        # this function is the funtion that gets called externally\n",
    "        # we can have this function as a ray method to help with distributed execution\n",
    "        pass\n",
    "\n",
    "    def get_available_stat_names(self):\n",
    "        # interacts with data object and returns requested data for inspection\n",
    "        pass\n",
    "\n",
    "    def update_channel_info(\n",
    "        self, stats_names: pd.DataFrame, factor: pd.DataFrame\n",
    "    ) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Updates the channel information for the relavent rows\n",
    "        based on th ID_FactorList information in stats_names\n",
    "\n",
    "        Args:\n",
    "            stats_names (pd.DataFrame): _description_\n",
    "            factor (pd.DataFrame): _description_\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: _description_\n",
    "        \"\"\"\n",
    "\n",
    "        # create function get channel number from a pandas row from stats_names\n",
    "        # inner func\n",
    "        def get_channel_id(row_info, factor: pd.DataFrame):\n",
    "            factor_id = row_info[\"ID_FactorList\"]  # factor id\n",
    "            name = row_info[\"Name\"]  # stat name\n",
    "\n",
    "            # filter factor to only include items related to Channel\n",
    "            channel_info = factor[factor[\"Name\"] == \"Channel\"]\n",
    "\n",
    "            # main logic to select the right channel given the factor id\n",
    "            if factor_id in channel_info[\"ID_List\"].to_list():\n",
    "                channel = channel_info[channel_info[\"ID_List\"] == factor_id][\n",
    "                    \"Level\"\n",
    "                ].item()\n",
    "                return f\"{name} Channel_{channel}\"\n",
    "            # if factor id is not in the channel list no channel info is needed\n",
    "            else:\n",
    "                return name\n",
    "\n",
    "        # create partial\n",
    "        get_channel_id_partial = partial(get_channel_id, factor=factor)\n",
    "\n",
    "        # update stats name with the newly mapped stats names values\n",
    "        stats_names[\"Name\"] = stats_names.apply(func=get_channel_id_partial, axis=1)\n",
    "\n",
    "        return stats_names\n",
    "\n",
    "    def update_surface_info(\n",
    "        self, stats_names: pd.DataFrame, factor: pd.DataFrame\n",
    "    ) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Updates the surface name information for the relavent rows\n",
    "        based on th ID_FactorList information in stats_names\n",
    "\n",
    "        Args:\n",
    "            stats_names (pd.DataFrame): _description_\n",
    "            factor (pd.DataFrame): _description_\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: _description_\n",
    "        \"\"\"\n",
    "\n",
    "        # create function get channel number from a pandas row from stats_names\n",
    "        # inner func\n",
    "        def get_surface_name(row_info, factor: pd.DataFrame):\n",
    "            factor_id = row_info[\"ID_FactorList\"]  # factor id\n",
    "            name = row_info[\"Name\"]  # stat name\n",
    "\n",
    "            # filter factor to only include items related to Channel\n",
    "            channel_info = factor[factor[\"Name\"] == \"Surfaces\"]\n",
    "\n",
    "            # main logic to select the right channel given the factor id\n",
    "            if factor_id in channel_info[\"ID_List\"].to_list():\n",
    "                channel = channel_info[channel_info[\"ID_List\"] == factor_id][\n",
    "                    \"Level\"\n",
    "                ].item()\n",
    "                return channel\n",
    "            # if factor id is not in the channel list no channel info is needed\n",
    "            else:\n",
    "                return name\n",
    "\n",
    "        # create partial\n",
    "        get_surface_name_partial = partial(get_surface_name, factor=factor)\n",
    "\n",
    "        # update stats name with the newly mapped stats names values\n",
    "        stats_names[\"Name\"] = stats_names.apply(func=get_surface_name_partial, axis=1)\n",
    "\n",
    "        return stats_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "surface_name: 9.330033208243549e-07\n",
      "stat_names: 5.69969997741282e-05\n",
      "stat_values: 6.175500311655924e-05\n",
      "object_id: 6.493899854831398e-05\n",
      "factor: 6.807000318076462e-05\n",
      "stat_names_channel: 3.286552268997184\n",
      "stat_names_surfaces: 5.98889851399872\n",
      "filtered_stat_values: 6.532022077000875\n",
      "organized_stats: 6.883267199002148\n",
      "stats_df: 6.9294647999995505\n"
     ]
    }
   ],
   "source": [
    "parser = TimeStepSurfaceParser(data_path)\n",
    "out = parser.process(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nih",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
