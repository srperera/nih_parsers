{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import yaml\n",
    "import os\n",
    "from collections.abc import MutableMapping\n",
    "from typing import Dict, List, Tuple\n",
    "from exceptions import *\n",
    "from copy import deepcopy\n",
    "from parser_base import Parser\n",
    "from imaris import ImarisDataObject\n",
    "import ray\n",
    "from functools import partial\n",
    "import time\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote\n",
    "class SurfaceParser(Parser):\n",
    "    \"\"\"\n",
    "    Extracts Surface Level Information From Imaris File\n",
    "\n",
    "    Args:\n",
    "        Parser (ABCMeta): Parser Abstract Base Class\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, ims_file_path: str) -> None:\n",
    "        self.ims_file_path = ims_file_path\n",
    "        self.ims = ImarisDataObject(self.ims_file_path)\n",
    "        self.configure_instance()\n",
    "\n",
    "    def configure_instance(self) -> None:\n",
    "        \"\"\"\n",
    "        Extracts relevant information from ims object and\n",
    "        instantiates it as instance variables for fast recall.\n",
    "\n",
    "        Currently Extracts:\n",
    "            - all the surface names -- List\n",
    "            - all the stats_names -- {id: pd.DataFrame}\n",
    "            - all the stats values -- {id: pd.DataFrame}\n",
    "            - all the factor info -- {id: pd.DataFrame}\n",
    "        \"\"\"\n",
    "        # extract all information and saves it as a instance var\n",
    "        self.surface_names = self.ims.get_object_names(\"Surface\")\n",
    "\n",
    "        # get all the stats names for every surface {surf_id: stats_name_df}\n",
    "        self.stats_names = {\n",
    "            surface_id: self.ims.get_stats_names(surface_name)\n",
    "            for surface_id, surface_name in enumerate(self.surface_names)\n",
    "        }\n",
    "\n",
    "        # get all the stats values for every surface {surf_id: stats_values_df}\n",
    "        self.stats_values = {\n",
    "            surface_id: self.ims.get_stats_values(surface_name)\n",
    "            for surface_id, surface_name in enumerate(self.surface_names)\n",
    "        }\n",
    "\n",
    "        # get all the factor table info for every surface {surf_id: factor_df}\n",
    "        self.factors = {\n",
    "            surface_id: self.ims.get_object_factor(surface_name)\n",
    "            for surface_id, surface_name in enumerate(self.surface_names)\n",
    "        }\n",
    "\n",
    "        # get all the factor table info for every surface {surf_id: factor_df}\n",
    "        self.object_ids = {\n",
    "            surface_id: self.ims.get_object_ids(surface_name)\n",
    "            for surface_id, surface_name in enumerate(self.surface_names)\n",
    "        }\n",
    "\n",
    "    def organize_stats(self, stats_values: pd.DataFrame) -> Dict:\n",
    "        \"\"\"Organized the data such that it looks like\n",
    "        {ID_Object: {Stats Name: Value}}\n",
    "\n",
    "        Args:\n",
    "            surface_stats_values (pd.DataFrame): a single dataframe\n",
    "            that contains the statistics for a single surface\n",
    "\n",
    "        Returns:\n",
    "            Dict: _description_\n",
    "        \"\"\"\n",
    "        grouped_stats = (\n",
    "            stats_values.groupby(\"ID_Object\")[[\"ID_StatisticsType\", \"Value\"]]\n",
    "            .apply(lambda x: x.set_index(\"ID_StatisticsType\").to_dict(orient=\"dict\"))\n",
    "            .to_dict()\n",
    "        )\n",
    "        grouped_stats = {k: v[\"Value\"] for k, v in grouped_stats.items()}\n",
    "        return grouped_stats\n",
    "\n",
    "    def generate_csv(\n",
    "        self, stats_values: Dict, stat_names: pd.DataFrame\n",
    "    ) -> pd.DataFrame:\n",
    "        \"\"\"_summary_\n",
    "\n",
    "        Args:\n",
    "            organized_stats (Dict): _description_\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: _description_\n",
    "        \"\"\"\n",
    "        # create a dict that maps stat_id to stat_name\n",
    "        column_names_dict = dict(zip(stat_names[\"ID\"], stat_names[\"Name\"]))\n",
    "        dataframe = pd.DataFrame(stats_values).transpose()\n",
    "\n",
    "        # replaces id columns with respective stat name and add idx\n",
    "        dataframe = dataframe.rename(column_names_dict, axis=1)\n",
    "        dataframe[\"Object_ID\"] = dataframe.index\n",
    "\n",
    "        return dataframe\n",
    "\n",
    "    def save_csv(self, surface_id: int, dataframe: pd.DataFrame, save_dir: str) -> None:\n",
    "        # a function to write csv information to disk\n",
    "        # get save_dir/original_filename.csv\n",
    "        ims_filename = os.path.basename(self.ims_file_path).split(\".\")[0]\n",
    "        ims_filename = f\"{ims_filename}_surface_{surface_id}.csv\"\n",
    "        save_filepath = os.path.join(save_dir, ims_filename)\n",
    "        dataframe.to_csv(save_filepath)\n",
    "\n",
    "    def process(self, surface_id: int) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Runs a single end to end parser pipeline on a single surface\n",
    "        Steps:\n",
    "            - get stat names for a single surface\n",
    "            - get stat values for a single surface\n",
    "            - filter stat values to keep only track ids\n",
    "            - filter stats values to remove track level stat information\n",
    "            - rename certian columns (if needed)(need a custom func for this to add channel info)\n",
    "            - organize the filtered stats\n",
    "            - generate csv\n",
    "            - save csv\n",
    "\n",
    "        Args:\n",
    "            surface_id (int): _description_\n",
    "        \"\"\"\n",
    "        # gather info for current surface\n",
    "        start = time.perf_counter()\n",
    "        surface_name = self.surface_names[surface_id]\n",
    "        stat_names = self.stats_names.get(surface_id)\n",
    "        stat_values = self.stats_values.get(surface_id)\n",
    "        object_id = self.object_ids.get(surface_id)\n",
    "        factor = self.factors.get(surface_id)\n",
    "\n",
    "        # update channel and surface names\n",
    "        stat_names = self.update_channel_info(stats_names=stat_names, factor=factor)\n",
    "        stat_names = self.update_surface_info(stats_names=stat_names, factor=factor)\n",
    "\n",
    "        # filter stats values by object ids (ie: ignore info related to trackids)\n",
    "        stat_values = self.filter_stats(\n",
    "            stats_values=stat_values,\n",
    "            filter_col_names=[\"ID_Object\"],\n",
    "            filter_values=[object_id],\n",
    "        )\n",
    "\n",
    "        # organize stats values\n",
    "        organized_stats = self.organize_stats(stat_values)\n",
    "\n",
    "        # generate csv\n",
    "        stats_df = self.generate_csv(organized_stats, stat_names=stat_names)\n",
    "\n",
    "        # add track id information for each object\n",
    "        stats_df = self.update_track_id_info(surface_name, stats_df)\n",
    "\n",
    "        return stats_df\n",
    "\n",
    "    def filter_stats(\n",
    "        self,\n",
    "        stats_values: pd.DataFrame,\n",
    "        filter_col_names: List[str],\n",
    "        filter_values: List[pd.Series],\n",
    "    ) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Filters the stats values dataframe. It keeps information\n",
    "        from col_names and filter_values that is passed in as arguments.\n",
    "\n",
    "        Args:\n",
    "            stats_values (pd.DataFrame): _description_\n",
    "            filter_col_name (str): name of the column we want to use to filter\n",
    "            filter_values (str): values that we want to keep\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: _description_\n",
    "        \"\"\"\n",
    "        # for surface parser need to filter out track id information\n",
    "        # and statistics related to track information.\n",
    "        for col_names, values in zip(filter_col_names, filter_values):\n",
    "            stats_values = stats_values[stats_values[col_names].isin(values=values)]\n",
    "\n",
    "        return stats_values\n",
    "\n",
    "    def extract_and_save(self, surface_id: int, save_dir: str) -> None:\n",
    "        # this function is the funtion that gets called externally\n",
    "        # we can have this function as a ray method to help with distributed execution\n",
    "        dataframe = self.process(surface_id)\n",
    "        self.save_csv(surface_id, dataframe, save_dir)\n",
    "\n",
    "    def update_stats_with_real_names(\n",
    "        self, surface_name: str, stats_names: Dict, user_defined_list: List\n",
    "    ) -> Dict:\n",
    "        \"\"\"\n",
    "        Update the stats names according to the real surface names found\n",
    "        inside Contents->SurfaceName->Factor\n",
    "\n",
    "        Args:\n",
    "            surface_name (str): the name of the surface to extract data from\n",
    "            stats_names (Dict): stats_names dictionary\n",
    "            user_defined_list (List): list of stats name given by ...\n",
    "                ...the user to be replaced by the real surface names\n",
    "\n",
    "        Returns:\n",
    "            Dict: stats name dict with the updated surface names\n",
    "        \"\"\"\n",
    "        real_stats_names = self.ims.get_real_surface_names(surface_name)\n",
    "        filtered_dicts = [\n",
    "            self.get_filtered_stat_names(stats_names, keyword, exact=True)\n",
    "            for keyword in user_defined_list\n",
    "        ]\n",
    "        for dict in filtered_dicts:\n",
    "            for idx, (k, _) in enumerate(dict.items()):\n",
    "                stats_names[k] = real_stats_names[idx]\n",
    "\n",
    "        return stats_names\n",
    "\n",
    "    def update_channel_info(\n",
    "        self, stats_names: pd.DataFrame, factor: pd.DataFrame\n",
    "    ) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Updates the channel information for the relavent rows\n",
    "        based on th ID_FactorList information in stats_names\n",
    "\n",
    "        Args:\n",
    "            stats_names (pd.DataFrame): _description_\n",
    "            factor (pd.DataFrame): _description_\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: _description_\n",
    "        \"\"\"\n",
    "\n",
    "        # create function get channel number from a pandas row from stats_names\n",
    "        # inner func\n",
    "        def get_channel_id(row_info, factor: pd.DataFrame):\n",
    "            factor_id = row_info[\"ID_FactorList\"]  # factor id\n",
    "            name = row_info[\"Name\"]  # stat name\n",
    "\n",
    "            # filter factor to only include items related to Channel\n",
    "            channel_info = factor[factor[\"Name\"] == \"Channel\"]\n",
    "\n",
    "            # main logic to select the right channel given the factor id\n",
    "            if factor_id in channel_info[\"ID_List\"].to_list():\n",
    "                channel = channel_info[channel_info[\"ID_List\"] == factor_id][\n",
    "                    \"Level\"\n",
    "                ].item()\n",
    "                return f\"{name} Channel_{channel}\"\n",
    "            # if factor id is not in the channel list no channel info is needed\n",
    "            else:\n",
    "                return name\n",
    "\n",
    "        # create partial\n",
    "        get_channel_id_partial = partial(get_channel_id, factor=factor)\n",
    "\n",
    "        # update stats name with the newly mapped stats names values\n",
    "        stats_names[\"Name\"] = stats_names.apply(func=get_channel_id_partial, axis=1)\n",
    "\n",
    "        return stats_names\n",
    "\n",
    "    def update_surface_info(\n",
    "        self,\n",
    "        stats_names: pd.DataFrame,\n",
    "        factor: pd.DataFrame,\n",
    "    ) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Updates the surface name information for the relavent rows\n",
    "        based on th ID_FactorList information in stats_names\n",
    "\n",
    "        Args:\n",
    "            stats_names (pd.DataFrame): _description_\n",
    "            factor (pd.DataFrame): _description_\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: _description_\n",
    "        \"\"\"\n",
    "\n",
    "        # create function get channel number from a pandas row from stats_names\n",
    "        # inner func\n",
    "        def get_surface_name(row_info, factor: pd.DataFrame):\n",
    "            factor_id = row_info[\"ID_FactorList\"]  # factor id\n",
    "            name = row_info[\"Name\"]  # stat name\n",
    "\n",
    "            # filter factor to only include items related to Channel\n",
    "            channel_info = factor[factor[\"Name\"] == \"Surfaces\"]\n",
    "\n",
    "            # main logic to select the right channel given the factor id\n",
    "            if factor_id in channel_info[\"ID_List\"].to_list():\n",
    "                channel = channel_info[channel_info[\"ID_List\"] == factor_id][\n",
    "                    \"Level\"\n",
    "                ].item()\n",
    "                return channel\n",
    "            # if factor id is not in the channel list no channel info is needed\n",
    "            else:\n",
    "                return name\n",
    "\n",
    "        # create partial\n",
    "        get_surface_name_partial = partial(get_surface_name, factor=factor)\n",
    "\n",
    "        # update stats name with the newly mapped stats names values\n",
    "        stats_names[\"Name\"] = stats_names.apply(func=get_surface_name_partial, axis=1)\n",
    "\n",
    "        return stats_names\n",
    "\n",
    "    def inspect(self, surface_id: int) -> Dict:\n",
    "        \"\"\"\n",
    "        Used to inspect intermediate steps in the\n",
    "        parser's process.\n",
    "\n",
    "        Args:\n",
    "            surface_id (int): _description_\n",
    "\n",
    "        Returns:\n",
    "            Dict: _description_\n",
    "        \"\"\"\n",
    "        storage = {}\n",
    "        surface_name = self.surface_names[surface_id]\n",
    "        storage[\"surface_name\"] = surface_name\n",
    "        stat_names = self.stats_names.get(surface_id)\n",
    "        storage[\"stat_names_raw\"] = deepcopy(stat_names)\n",
    "        stat_values = self.stats_values.get(surface_id)\n",
    "        storage[\"stat_values_raw\"] = stat_values\n",
    "        object_id = self.object_ids.get(surface_id)\n",
    "        factor = self.factors.get(surface_id)\n",
    "        storage[\"factor\"] = factor\n",
    "\n",
    "        # update channel and surface names\n",
    "        stat_names = self.update_channel_info(stats_names=stat_names, factor=factor)\n",
    "        storage[\"stat_names_channel_added\"] = deepcopy(stat_names)\n",
    "        stat_names = self.update_surface_info(stats_names=stat_names, factor=factor)\n",
    "        storage[\"stat_names_surface_added\"] = deepcopy(stat_names)\n",
    "\n",
    "        # # filter stats values by object ids (ie: ignore info related to trackids)\n",
    "        stat_values = self.filter_stats(\n",
    "            stats_values=stat_values,\n",
    "            filter_col_names=[\"ID_Object\"],\n",
    "            filter_values=[object_id],\n",
    "        )\n",
    "\n",
    "        # organize stats values\n",
    "        organized_stats = self.organize_stats(stat_values)\n",
    "        storage[\"organized_stats\"] = organized_stats\n",
    "\n",
    "        # generate csv\n",
    "        stats_df = self.generate_csv(organized_stats, stat_names=stat_names)\n",
    "        storage[\"stats_df\"] = stats_df\n",
    "\n",
    "        # add track id information for each object\n",
    "        stats_df = self.update_track_id_info(surface_name, stats_df)\n",
    "\n",
    "        storage[\"final_df\"] = stats_df\n",
    "\n",
    "        # garbage collection for memoery improvements\n",
    "        # is this needed?\n",
    "        del stat_names\n",
    "        del stat_values\n",
    "        del object_id\n",
    "        del factor\n",
    "        del organized_stats\n",
    "        del stats_df\n",
    "        gc.collect()\n",
    "\n",
    "        return storage\n",
    "\n",
    "    def update_track_id_info(self, surface_name, dataframe) -> pd.DataFrame:\n",
    "        \"\"\"Returns the track id an object belongs to\n",
    "\n",
    "        Args:\n",
    "            object_id (int): _description_\n",
    "\n",
    "        Returns:\n",
    "            int: _description_\n",
    "        \"\"\"\n",
    "        object_info = self.ims.get_object_info(surface_name)\n",
    "        track_info = self.ims.get_track_info(surface_name)\n",
    "\n",
    "        # create database to make obj to track matching efficient\n",
    "        database = {}\n",
    "        for idx in range(len(track_info)):\n",
    "            data = track_info.iloc[idx]\n",
    "            start = data[\"IndexTrackObjectBegin\"]\n",
    "            end = data[\"IndexTrackObjectEnd\"]\n",
    "            track_id = data[\"ID\"]\n",
    "            for i in range(start, end):\n",
    "                obj_id = object_info.iloc[i][\"ID\"]\n",
    "                database[obj_id] = track_id\n",
    "\n",
    "        dataframe[\"Track_ID\"] = dataframe.apply(\n",
    "            func=lambda x: database[x[\"Object_ID\"].item()],\n",
    "            axis=1,\n",
    "        )\n",
    "\n",
    "        return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = (\n",
    "    \"../../data/multi_surface_track_parser_dev_data/GFP #1 Sec1 Roi2 2x2 1h30min.ims\"\n",
    ")\n",
    "os.path.isfile(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-12 22:49:05,371\tINFO worker.py:1621 -- Started a local Ray instance.\n"
     ]
    }
   ],
   "source": [
    "ims = ImarisDataObject(data_path)\n",
    "num_surfaces = len(ims.get_object_names(\"Surface\"))\n",
    "actors = [SurfaceParser.remote(data_path) for _ in range(num_surfaces)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = ray.get(\n",
    "    [actor.extract_and_save.remote(idx, \".\") for idx, actor in enumerate(actors)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in results:\n",
    "    print(i[\"surface_name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "\n",
    "def run_parser_parallel(data_path: str, save_dir: str = None):\n",
    "    \"\"\"Runs all the surfaces in an ims file in parallel\n",
    "\n",
    "    Args:\n",
    "        data_path (_type_): str path to ims object\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "    # get number of surfaces in object\n",
    "    ims_obj = ImarisDataObject(data_path)\n",
    "    num_surfaces = len(ims_obj.get_object_names(\"Surface\"))\n",
    "\n",
    "    # run garbage collection and free up memory\n",
    "    del ims_obj\n",
    "    gc.collect()\n",
    "\n",
    "    # run ray\n",
    "    actors = [SurfaceParser.remote(data_path) for _ in range(num_surfaces)]\n",
    "    results = ray.get([actor.inspect.remote(idx) for idx, actor in enumerate(actors)])\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Yaml file should have\n",
    "    * a list of directories with ims files in each dir.\n",
    "    * a list of save paths for each directory, OR a single folder dir where we will create a folder for each filename and populate the information inside each. \n",
    "    * an indicator that says Surface, Track, X Surface, and Surface/Track ID.\n",
    "    * If X Surface specify which surface.\n",
    "    * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "corev2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
