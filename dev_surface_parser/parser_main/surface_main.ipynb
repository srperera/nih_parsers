{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.21.0\n"
     ]
    }
   ],
   "source": [
    "import utils\n",
    "import numpy as np\n",
    "import glob \n",
    "import os\n",
    "import pandas as pd\n",
    "print(np.__version__)\n",
    "from surface_parser_v2 import extract_and_save\n",
    "import ray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get Available Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def available_categories(ims_file_path: str, valid_surface: int):\n",
    "    \n",
    "    # load the imaris file\n",
    "    data = utils.load_ims(ims_file_path)\n",
    "    \n",
    "    # get surface we want to parse\n",
    "    surface_name = utils.get_object_names(full_data_file=data, \n",
    "                                           search_for='Surface')[valid_surface]\n",
    "    \n",
    "    # get all the statistics names\n",
    "    surface_stats_names = utils.get_statistics_names(full_data_file=data, object_name=surface_name)\n",
    "    \n",
    "    # invert dictionary + name modifications\n",
    "    # this step is a cosmetic step\n",
    "    inverted_stats_names = utils.invert_stats_dict(surface_stats_names)\n",
    "    inverted_stats_names = utils.flatten(inverted_stats_names)\n",
    "        \n",
    "    # reverse the stats names again such that key=num, value=name\n",
    "    #final_stats_names = {v: k for k,v in inverted_stats_names.items()}\n",
    "    \n",
    "    np.savetxt('stats_categories_new.txt', list(inverted_stats_names.keys()), fmt='%s')\n",
    "        \n",
    "    print(f'Saved Stats Categories in directory: {os.path.dirname(os.path.abspath(ims_file_path))}')\n",
    "    \n",
    "    #return list(inverted_stats_names.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_available_categories(config_path: str):\n",
    "    \n",
    "    # load config path\n",
    "    yaml = utils.load_yaml('config.yaml')\n",
    "\n",
    "    # files to scan\n",
    "    directories = yaml['data_dir']\n",
    "    \n",
    "    # valid surface\n",
    "    valid_surface = int(yaml['valid_surface']) - 1\n",
    "    \n",
    "    for directory in directories:\n",
    "        \n",
    "        # grab all the files in the directory w/ .ims\n",
    "        filenames = list(glob.glob(os.path.join(directory, '*.ims')))\n",
    "                \n",
    "        for filename in filenames: \n",
    "            \n",
    "            # file path\n",
    "            file_path = filename\n",
    "            \n",
    "            #print(file_path, filename, 'dafd')\n",
    "            \n",
    "            # get and save the available categories csv file\n",
    "            available_categories(file_path, valid_surface)\n",
    "            \n",
    "            break\n",
    "        \n",
    "        break\n",
    "    \n",
    "    print('[info] Please Edit The Statistics File')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN GENERATE CATEGORIES\n",
    "#generate_available_categories('config.yaml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate Statistics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_statistics(config_path: str):\n",
    "    \n",
    "    # load config path\n",
    "    yaml = utils.load_yaml('config.yaml')\n",
    "\n",
    "    # files to scan\n",
    "    directories = yaml['data_dir']\n",
    "    \n",
    "    # get the stats categories\n",
    "    stats_categories = utils.read_txt(yaml['stats_category_path'])\n",
    "    \n",
    "    # valid surface\n",
    "    valid_surface = int(yaml['valid_surface']) - 1\n",
    "    \n",
    "    # create a list to hold ray subprocess\n",
    "    processes = []\n",
    "    \n",
    "    for directory in directories:\n",
    "        \n",
    "        # grab all the files in the directory w/ .ims\n",
    "        filenames = list(glob.glob(os.path.join(directory, '*.ims')))\n",
    "        \n",
    "        for filename in filenames:\n",
    "                        \n",
    "            # file path\n",
    "            file_path = filename #os.path.join(directory, filename)\n",
    "            \n",
    "            # save_file_path\n",
    "            save_path = os.path.splitext(filename)[0] + '.csv'\n",
    "            #save_path = os.path.join(directory, save_path)\n",
    "            \n",
    "            # extract and save\n",
    "            processes.append(extract_and_save.remote(file_path, valid_surface, stats_categories, save_path))\n",
    "            \n",
    "    print('info -- running subprocesses:')\n",
    "    \n",
    "    ray.get(processes) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "info -- running subprocesses:\n",
      "\u001b[2m\u001b[36m(extract_and_save pid=70134)\u001b[0m [info] working on file ../data/Surface_parser_column_swap_issue/Exp116-BACH1IKO42dpi_clec4f+tim4_10202022_New_[ii39_F480-AF532_FMO_3D_Merged_Image_40]_[ims1_2022-11-14T13-54-07.151].ims\n",
      "\u001b[2m\u001b[36m(extract_and_save pid=70140)\u001b[0m [info] working on file ../data/Surface_parser_column_swap_issue/Exp116-BACH1IKO42dpi_clec4f+tim4_10202022_New_[ii174_WTLi4_Merged_Image_175]_[ims1_2022-11-14T13-54-07.151].ims\n",
      "\u001b[2m\u001b[36m(extract_and_save pid=70129)\u001b[0m [info] working on file ../data/Surface_parser_column_swap_issue/Exp116-BACH1IKO42dpi_clec4f+tim4_10202022_New_[ii56_WTLi1_Merged_Image_57]_[ims1_2022-11-14T13-54-07.151].ims\n",
      "\u001b[2m\u001b[36m(extract_and_save pid=70134)\u001b[0m --- [warning] -- user requested category ID is NOT in current file\n",
      "\u001b[2m\u001b[36m(extract_and_save pid=70134)\u001b[0m [info] finished! \n",
      "\u001b[2m\u001b[36m(extract_and_save pid=70134)\u001b[0m \n",
      "\u001b[2m\u001b[36m(extract_and_save pid=70140)\u001b[0m --- [warning] -- user requested category ID is NOT in current file\n",
      "\u001b[2m\u001b[36m(extract_and_save pid=70140)\u001b[0m [info] finished! \n",
      "\u001b[2m\u001b[36m(extract_and_save pid=70140)\u001b[0m \n",
      "\u001b[2m\u001b[36m(extract_and_save pid=70129)\u001b[0m --- [warning] -- user requested category ID is NOT in current file\n"
     ]
    }
   ],
   "source": [
    "# RUN GENERATE STATISTICS\n",
    "generate_statistics(config_path='config.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(extract_and_save pid=70129)\u001b[0m [info] finished! \n",
      "\u001b[2m\u001b[36m(extract_and_save pid=70129)\u001b[0m \n"
     ]
    }
   ],
   "source": [
    "# Working "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('core')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "04aae946aefb73757d94e4e7bfb7ede85957aa0149a3e71cc39e2fcc66c8e46e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
