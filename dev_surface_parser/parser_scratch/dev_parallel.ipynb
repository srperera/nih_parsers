{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "import numpy as np\n",
    "import glob \n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_and_save(ims_file_path: str, valid_surface: int, categories_list: list, save_path: str) -> None:\n",
    "    \n",
    "    # load the imaris file\n",
    "    data = utils.load_ims(ims_file_path)\n",
    "    \n",
    "    # get surface we want to parse\n",
    "    surface_name = utils.get_object_names(full_data_file=data, \n",
    "                                           search_for='Surface')[valid_surface]\n",
    "    \n",
    "    # get all the statistics names\n",
    "    surface_stats_names = utils.get_statistics_names(full_data_file=data, object_name=surface_name)\n",
    "    \n",
    "    # get the statistics values in the surface\n",
    "    surface_stats_values = utils.get_stats_values(full_data_file=data, object_name=surface_name)\n",
    "    \n",
    "    # create a empty dict where key=numeric stats ids and value = None\n",
    "    # this dictionary is simply a container to store all the statistics values\n",
    "    empty_stats_dict = {key: None for key in surface_stats_names.keys()}   \n",
    "    \n",
    "    # create a empty dict where key=object_id, and value=empty stats dict\n",
    "    # this dictionary is a container where for each object in the surface ..\n",
    "    # .. it contains another dictionary that stores all the stats values\n",
    "    empty_data_dict = {key: empty_stats_dict for key in surface_stats_values['ID_Object'].keys()}\n",
    "    \n",
    "    # start data extraction in the loop below\n",
    "    for index in range(len(surface_stats_values)):\n",
    "        \n",
    "        # get the current data points \n",
    "        current_data = surface_stats_values.iloc[index]\n",
    "        \n",
    "        # get the object id the data is associated with\n",
    "        object_id = current_data['ID_Object']\n",
    "        \n",
    "        # get the type of the value\n",
    "        stats_type = current_data['ID_StatisticsType']\n",
    "        \n",
    "        # get the statistics value\n",
    "        value = current_data['Value']\n",
    "        \n",
    "        # insert current selection into dictionary\n",
    "        try:\n",
    "            empty_data_dict[object_id][stats_type] = value\n",
    "        except KeyError:\n",
    "            # key error occurs if for a stats name there is no value\n",
    "            # missing values will be represented as None\n",
    "            pass\n",
    "        \n",
    "    # invert dictionary + name modifications\n",
    "    # this step is a cosmetic step\n",
    "    inverted_stats_names = utils.invert_stats_dict(surface_stats_names)\n",
    "    inverted_stats_names = utils.flatten(inverted_stats_names)\n",
    "    \n",
    "    # create a list of stats names (in integer form) we want to remove\n",
    "    del_list = utils.create_del_list(inverted_stats_names, categories_list)\n",
    "    \n",
    "    # reverse the stats names again such that key=num, value=name\n",
    "    final_stats_names = {v: k for k,v in inverted_stats_names.items()}\n",
    "    \n",
    "    # generate csv\n",
    "    dataframe = utils.generate_csv(data_dict=empty_data_dict, \n",
    "                                   del_list=del_list,\n",
    "                                   stats_names=final_stats_names,\n",
    "                                   categories_list=categories_list)\n",
    "    \n",
    "    \n",
    "    # save the dataframe in the same location\n",
    "    #dataframe.to_csv(save_path)\n",
    "    \n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_available_categories(ims_file_path: str, valid_surface: int):\n",
    "    \n",
    "    # load the imaris file\n",
    "    data = utils.load_ims(ims_file_path)\n",
    "    \n",
    "    # get surface we want to parse\n",
    "    surface_name = utils.get_object_names(full_data_file=data, \n",
    "                                           search_for='Surface')[valid_surface]\n",
    "    \n",
    "    # get all the statistics names\n",
    "    surface_stats_names = utils.get_statistics_names(full_data_file=data, object_name=surface_name)\n",
    "    \n",
    "    # invert dictionary + name modifications\n",
    "    # this step is a cosmetic step\n",
    "    inverted_stats_names = utils.invert_stats_dict(surface_stats_names)\n",
    "    inverted_stats_names = utils.flatten(inverted_stats_names)\n",
    "        \n",
    "    # reverse the stats names again such that key=num, value=name\n",
    "    #final_stats_names = {v: k for k,v in inverted_stats_names.items()}\n",
    "    \n",
    "    np.savetxt('stats_categories.txt', list(inverted_stats_names.keys()), fmt='%s')\n",
    "    \n",
    "    #return list(inverted_stats_names.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = [\n",
    "    'Position X',\n",
    "    'Position Y',\n",
    "    'Position Z',\n",
    "    'Intensity Mean_channel_1',\n",
    "    'Intensity Mean_channel_2',\n",
    "    'Intensity Mean_channel_3',\n",
    "    'Intensity Mean_channel_4',\n",
    "    'Intensity Mean_channel_5',\n",
    "]\n",
    "\n",
    "valid_surface = 6\n",
    "\n",
    "file_path = '../data/P1 DHBR Roi3 6x6_TileScan_001_Merging_Crop_0_batch.ims'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "available_categories = generate_available_categories(file_path, valid_surface)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = extract_and_save(file_path, valid_surface, categories, '.')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(config_path: str):\n",
    "    \n",
    "    # load config path\n",
    "    yaml = utils.load_yaml('config.yaml')\n",
    "\n",
    "    # files to scan\n",
    "    directories = yaml['data_dir']\n",
    "    \n",
    "    # get the stats categories\n",
    "    stats_categories = utils.read_txt(yaml['stats_category_path'])\n",
    "    \n",
    "    # valid surface\n",
    "    valid_surface = int(yaml['valid_surface'])\n",
    "    \n",
    "    for directory in directories:\n",
    "        \n",
    "        # grab all the files in the directory w/ .ims\n",
    "        filenames = list(glob.glob(os.path.join(directory, '*.ims')))\n",
    "        \n",
    "        for filename in filenames: \n",
    "            \n",
    "            # file path\n",
    "            file_path = os.path.join(directory, filename)\n",
    "            \n",
    "            # save_file_path\n",
    "            save_path = os.path.splitext(filename)[0] + '.csv'\n",
    "            save_path = os.path.join(directory, save_path)\n",
    "            \n",
    "            # extract and save\n",
    "            extract_and_save(file_path, valid_surface, stats_categories, save_path)\n",
    "\n",
    "run('config.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "yaml = utils.load_yaml('config.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data_dir': ['../data/'],\n",
       " 'stats_category_path': 'stats_categories.txt',\n",
       " 'valid_surface': '6'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'float' object has no attribute 'strip'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/shehan/Documents/nih/parser_june_2022/parser/dev_parallel.ipynb Cell 10'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bshehan/home/shehan/Documents/nih/parser_june_2022/parser/dev_parallel.ipynb#ch0000009vscode-remote?line=0'>1</a>\u001b[0m utils\u001b[39m.\u001b[39;49mread_txt(yaml[\u001b[39m'\u001b[39;49m\u001b[39mstats_category_path\u001b[39;49m\u001b[39m'\u001b[39;49m])\n",
      "File \u001b[0;32m~/Documents/nih/parser_june_2022/parser/utils.py:35\u001b[0m, in \u001b[0;36mread_txt\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     33\u001b[0m data \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(path, sep\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m, header\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, names\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mStatistics\u001b[39m\u001b[39m'\u001b[39m])[\u001b[39m'\u001b[39m\u001b[39mStatistics\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mvalues\u001b[39m.\u001b[39mtolist()\n\u001b[1;32m     34\u001b[0m \u001b[39m# remove unwanted tabs\u001b[39;00m\n\u001b[0;32m---> 35\u001b[0m \u001b[39mreturn\u001b[39;00m [x\u001b[39m.\u001b[39mstrip(\u001b[39m'\u001b[39m\u001b[39m\\t\u001b[39;00m\u001b[39m'\u001b[39m) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m data]\n",
      "File \u001b[0;32m~/Documents/nih/parser_june_2022/parser/utils.py:35\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     33\u001b[0m data \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(path, sep\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m, header\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, names\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mStatistics\u001b[39m\u001b[39m'\u001b[39m])[\u001b[39m'\u001b[39m\u001b[39mStatistics\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mvalues\u001b[39m.\u001b[39mtolist()\n\u001b[1;32m     34\u001b[0m \u001b[39m# remove unwanted tabs\u001b[39;00m\n\u001b[0;32m---> 35\u001b[0m \u001b[39mreturn\u001b[39;00m [x\u001b[39m.\u001b[39;49mstrip(\u001b[39m'\u001b[39m\u001b[39m\\t\u001b[39;00m\u001b[39m'\u001b[39m) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m data]\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'float' object has no attribute 'strip'"
     ]
    }
   ],
   "source": [
    "utils.read_txt(yaml['stats_category_path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(yaml['stats_category_path'], header=None, names=['Statistics'])['Statistics'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('core')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "04aae946aefb73757d94e4e7bfb7ede85957aa0149a3e71cc39e2fcc66c8e46e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
